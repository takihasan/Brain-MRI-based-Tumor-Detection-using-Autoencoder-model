{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is Autoencoders"},{"metadata":{},"cell_type":"markdown","source":"Autoencoders is type of neual network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install imutils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n# Libraries\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport glob\nimport numpy as np \nimport pandas as pd \nimport os\nfrom os import listdir\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport imutils    \n\nfrom tensorflow.keras.models import Model,load_model\nfrom tensorflow.keras.layers import Conv2D,Input,ZeroPadding2D,BatchNormalization,Flatten,Activation,Dense,MaxPooling2D\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle #shuffling the data improves the model\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import MaxPooling2D, Dropout, UpSampling2D","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Image Dir settings\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_dir=\"../input/brain-mri-images-for-brain-tumor-detection/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nimg = cv2.imread('../input/brain-mri-images-for-brain-tumor-detection/yes/Y1.jpg', 0)\nplt.imshow(img, cmap='gray')\nprint(img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Yes_IMAGES = glob.glob('../input/brain-mri-images-for-brain-tumor-detection/yes/*.jpg')\nNo_IMAGES = glob.glob('../input/brain-mri-images-for-brain-tumor-detection/no/*.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(path):\n    image_list = np.zeros((len(path), 258, 540, 1))\n    for i, fig in enumerate(path):\n        img = image.load_img(fig, color_mode='grayscale', target_size=(258, 540))\n        x = image.img_to_array(img).astype('float32')\n        x = x / 255.0\n        image_list[i] = x\n    \n    return image_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n# Dataset Spliting\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = load_image(Yes_IMAGES)\ny_train = load_image(Yes_IMAGES)\nx_test = load_image(No_IMAGES)\n\nprint(x_train.shape, x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_val_split(x_train, y_train):\n    rnd = np.random.RandomState(seed=42)\n    perm = rnd.permutation(len(x_train))\n    train_idx = perm[:int(0.8 * len(x_train))]\n    val_idx = perm[int(0.8 * len(x_train)):]\n    return x_train[train_idx], y_train[train_idx], x_train[val_idx], y_train[val_idx]\n\nx_train, y_train, x_val, y_val = train_val_split(x_train, y_train)\nprint(x_train.shape, x_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Creating Autoencoder Class\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Autoencoder():\n    def __init__(self):\n        self.img_rows = 258\n        self.img_cols = 540\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        \n        optimizer = Adam(lr=0.001)\n        \n        self.autoencoder_model = self.build_model()\n        self.autoencoder_model.compile(loss='mse', optimizer=optimizer)\n        self.autoencoder_model.summary()\n    \n    def build_model(self):\n        input_layer = Input(shape=self.img_shape)\n        \n        # encoder\n        h = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n        h = MaxPooling2D((2, 2), padding='same')(h)\n        \n        # decoder\n        h = Conv2D(64, (3, 3), activation='relu', padding='same')(h)\n        h = UpSampling2D((2, 2))(h)\n        output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(h)\n        \n        return Model(input_layer, output_layer)\n    \n    def train_model(self, x_train, y_train, x_val, y_val, epochs, batch_size=20):\n        early_stopping = EarlyStopping(monitor='val_loss',\n                                       min_delta=0,\n                                       patience=5,\n                                       verbose=1, \n                                       mode='auto')\n        history = self.autoencoder_model.fit(x_train, y_train,\n                                             batch_size=batch_size,\n                                             epochs=epochs,\n                                             validation_data=(x_val, y_val),\n                                             callbacks=[early_stopping])\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.title('Model loss')\n        plt.ylabel('Loss')\n        plt.xlabel('Epoch')\n        plt.legend(['Train', 'Test'], loc='upper left')\n        plt.show()\n    \n    def eval_model(self, x_test):\n        preds = self.autoencoder_model.predict(x_test)\n        return preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n# Model Training\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ae = Autoencoder()\nae.train_model(x_train, y_train, x_val, y_val, epochs=200, batch_size=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n# Predictions\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = ae.eval_model(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_0 = preds[10] * 255.0\npreds_0 = preds_0.reshape(258, 540)\nx_test_0 = x_test[10] * 255.0\nx_test_0 = x_test_0.reshape(258, 540)\nplt.imshow(x_test_0, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(preds_0, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(preds_0, cmap='bone')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = preds.reshape(-1, 258, 540)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_1 = preds[20] * 255.0\npreds_1 = preds_1.reshape(258, 540)\n\nplt.imshow(preds_1, cmap='PiYG')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_2 = preds[50] * 255.0\npreds_2 = preds_2.reshape(258, 540)\n\nplt.imshow(preds_1, cmap='twilight')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}